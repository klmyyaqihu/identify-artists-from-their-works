## Folder 2: classification-VGG16 (with GPU)
* `1_Vgg16_30class_untune.ipynb`: In this part, we loads all qualified data (30 classes) in VGG16 without tuning. However, there exists severe overfitting by only using the VGG16. To address overfiting, we decide to first use 3 classes train a better model. And then, we go back to 30 classes and compare the results with this untuning version.
* `2_Vgg16_3class_untune.ipynb`: In this part, we only loads 3 classes with most paintings in VGG16 and still without tuning, because we need to compare it with the other tuned versions. Though this time we only run 20 epochs, we can still see there exists overfitting.
* `3_Vgg16_3class_test1 (overfitting).ipynb`: For this part, we loads 3 classes with most paintings in VGG16 and adds several layers to test the performance. Still, run 20 epochs. However, at the end of this test1, we can still clearly see overfitting.
* `4_Vgg16_3class_test2 (best fitting).ipynb`: For this part, we still loads 3 classes with most paintings in VGG16 while adds two more layers than test1. Still, run 20 epochs. Fortunately, at the end of this test2, we got nicer loss curves which reflects no obvious overfitting.
* `5_Vgg16_3class_test3 (underfitting).ipynb`: For this part, we still loads 3 classes with most paintings in VGG16 while adds two more layers than test2. Still, run 20 epochs. However, at the end of test3, we end up to an obvious underfitting.
* `6_Vgg16_3class_test2_validation1.ipynb`: Based on all three tests' results, the test2 has the best performance. Thus, we decide to repeat the test2's model two more times which verify the modle may work well on 30 classes. This is the validation1.
* `7_Vgg16_3class_test2_validation2.ipynb`: This is the validation2 of test2.
* `8_test_3class_result_summary.ipynb`: For this part, we compare the results of all test models for 3 classes: untuned, test1, test2, and test3. We will use the `loss`, `val_loss`, `acc`, and `val_acc` from former tests. And `test2` is the best fitting.
* `9_Vgg16_30class_by_test2_model`: Finally, we use the model from test2 to classify 30 artists' paintings with 120 epochs. And the validation accuraccy is stable at more than %60, and the validation loss keep decreasing during the 120 epochs while keep reasonable difference between the training loss. Given that there are 30 classes and some of the artists have similar art style, the accuracy of 60% is an acceptable result.
* `10_30class_result_summary`: For this part, we compare the results two models for 3 classes: untuned, and the model from test2. We will use the loss, val_loss, acc, and val_acc from the former tests. From the untuned_loss_curve, the val_loss keep increasing during all 120 epoch, which reflects severe overfitting; By comparison, from the test2_loss_curve, the val_loss keep decreasing during the 120 epochs which is what we expect.
<p align="center"><img src="https://github.com/klmyyaqihu/identify-artists-from-their-works/raw/master/figures/30class_result_summary_1.png" height="95%" width="95%"> </p >
<p align="center"><img src="https://github.com/klmyyaqihu/identify-artists-from-their-works/raw/master/figures/30class_result_summary_2.png" height="48%" width="48%"> </p >
